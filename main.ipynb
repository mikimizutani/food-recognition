{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikimizutani/food-recognition/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgeWszt1eYFo"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chVYpj_BBIDQ",
        "outputId": "e1bf0c9e-2d86-410a-e8d2-2b819a19bbac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "%cd /content/drive/My Drive/food-recognition/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive/food-recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlDZn5aAAHl-"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/food-recognition/')\n",
        "import classes\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from classes import FoodDataset\n",
        "from classes import FocalTverskyLoss\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "import torchvision\n",
        "#from engine import train_one_epoch, evaluate\n",
        "#import utils"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFf43BUTu5YW"
      },
      "source": [
        "training_path = '/content/drive/My Drive/food-recognition/dataset/train/images.zip'\n",
        "\n",
        "!ls\n",
        "!cp \"{training_path}\" .\n",
        "!unzip -n images.zip -d \"/content/drive/My Drive/food-recognition/dataset/train/\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZVyFxZkC94t"
      },
      "source": [
        "img = plt.imread(\"./dataset/train/images/021517.jpg\")\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr-rR8rsezy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d3e548-15e8-497f-a1b8-8bea301ad432"
      },
      "source": [
        "def to_tensor():\n",
        "    #Resizes images and boxes\n",
        "    tensors = [torchvision.transforms.Resize((100,100)), torchvision.transforms.ToTensor()]\n",
        "    return torchvision.transforms.Compose(tensors)\n",
        "\n",
        "\n",
        "#Method to view image with the categories\n",
        "def visualise_annotations(coco):\n",
        "    # nms = set([cat['supercategory'] for cat in cats])\n",
        "    catIds = coco.getCatIds()\n",
        "    imgIds = coco.getImgIds()\n",
        "    img = coco.loadImgs(imgIds[np.random.randint(0, len(imgIds))])[0]\n",
        "    image = mpimg.imread(os.path.join('./dataset/train/images/', str(img['file_name'])))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "    annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
        "    anns = coco.loadAnns(annIds)\n",
        "    coco.showAnns(anns)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# def train(model, device, train_loader, optimizer):\n",
        "#     model.train()\n",
        "#     y_true = []\n",
        "#     y_pred = []\n",
        "#     for i in train_loader:\n",
        "#\n",
        "#         # LOADING THE DATA IN A BATCH\n",
        "#         data, target = i\n",
        "#\n",
        "#         # MOVING THE TENSORS TO THE CONFIGURED DEVICE\n",
        "#         data, target = data.to(device), target.to(device)\n",
        "#\n",
        "#         # FORWARD PASS\n",
        "#         output = model(data.float())\n",
        "#         loss = FocalTverskyLoss(output)\n",
        "#         #loss = criterion(output, target.unsqueeze(1))\n",
        "#\n",
        "#         # BACKWARD AND OPTIMIZE\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#\n",
        "#         # PREDICTIONS\n",
        "#         pred = np.round(output.detach())\n",
        "#         target = np.round(target.detach())\n",
        "#         y_pred.extend(pred.tolist())\n",
        "#         y_true.extend(target.tolist())\n",
        "#\n",
        "#         print(\"Accuracy on training set is\",\n",
        "#               accuracy_score(y_true, y_pred))\n",
        "\n",
        "\n",
        "def val(model, device, test_loader):\n",
        "    # model in eval mode skips Dropout etc\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    # set the requires_grad flag to false as we are in the test mode\n",
        "    with torch.no_grad():\n",
        "        for i in test_loader:\n",
        "            # LOAD THE DATA IN A BATCH\n",
        "            data, target = i\n",
        "\n",
        "            # moving the tensors to the configured device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # the model on the data\n",
        "            output = model(data.float())\n",
        "\n",
        "            # PREDICTIONS\n",
        "            pred = np.round(output)\n",
        "            target = target.float()\n",
        "            y_true.extend(target.tolist())\n",
        "            y_pred.extend(pred.reshape(-1).tolist())\n",
        "\n",
        "    print(\"Accuracy on test set is\", accuracy_score(y_true, y_pred))\n",
        "    print(\"***********************************************************\")\n",
        "\n",
        "\n",
        "def accuracy_score(true, pred):\n",
        "    #TODO\n",
        "    return\n",
        "\n",
        "\n",
        "def get_model_instance_segmentation():\n",
        "    num_classes = 274\n",
        "        # load an instance segmentation model pre-trained pre-trained on COCO\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "    # get number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    # now get the number of input features for the mask classifier\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    # and replace the mask predictor with a new one\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
        "                                                       hidden_layer,\n",
        "                                                       num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    training_json = './dataset/train/annotations.json'\n",
        "    training_path = './dataset/train/images/'\n",
        "    #test_path = './dataset/val/images'\n",
        "    #test_json = './dataset/val/annotations.json'\n",
        "\n",
        "    #Use this block to see all the different food classes we have\n",
        "    #coco = COCO(training_json)\n",
        "    #ann_ids = coco.getAnnIds(imgIds=69996)\n",
        "#3#cats = coco.loadAnns(ann_ids)\n",
        "    #ann = coco.loadAnns(ann_ids)\n",
        "\n",
        "    #t = coco.imgs[ann['image_id']]\n",
        "\n",
        "    #print(v: i + 1 for i, v in enumerate(sorted(self.coco.getCatIds())))\n",
        "    #nms = [cat['name'] for cat in cats]\n",
        "    #print(cats)\n",
        "\n",
        "    #sys.exit()\n",
        "\n",
        "    #visualise_annotations()\n",
        "    num_epochs = 1\n",
        "\n",
        "    training_data = FoodDataset(root=training_path, annotation=training_json, transforms=to_tensor())\n",
        "    #validation_data = FoodDataset(root=test_path, annotation=test_json, transforms=to_tensor())\n",
        "    training_dataloader = DataLoader(training_data, batch_size=10, shuffle=True, collate_fn=training_data.collate_fn)\n",
        "    #validation_dataloader = DataLoader(validation_data, batch_size=64, shuffle=True)\n",
        "    \n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    # get the model using our helper function\n",
        "    model = get_model_instance_segmentation()\n",
        "\n",
        "    # move model to the right device\n",
        "    model.to(device)\n",
        "\n",
        "    # construct an optimizer\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                                momentum=0.9, weight_decay=0.00001)\n",
        "    # and a learning rate scheduler\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                                   step_size=3,\n",
        "                                                   gamma=0.1)\n",
        "\n",
        "    for i in range(num_epochs):\n",
        "        model.train()\n",
        "        i = 0\n",
        "        for imgs, annotations in training_dataloader:\n",
        "            i += 1\n",
        "            imgs = list(img.to(device) for img in imgs)\n",
        "            annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
        "            loss_dict = model(imgs, annotations)\n",
        "            losses = sum(loss for loss in list(loss_dict.values()))\n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "            torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            print(f'Iteration: {i}/{len(training_dataloader)}, Loss: {losses}')\n",
        "\n",
        "    print(\"That's it!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.67s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1/2412, Loss: 118.05221557617188\n",
            "Iteration: 2/2412, Loss: 100.32484436035156\n",
            "Iteration: 3/2412, Loss: 45.39422607421875\n",
            "Iteration: 4/2412, Loss: 36.93073272705078\n",
            "Iteration: 5/2412, Loss: 52.050968170166016\n",
            "Iteration: 6/2412, Loss: 54.63785171508789\n",
            "Iteration: 7/2412, Loss: 45.939327239990234\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}